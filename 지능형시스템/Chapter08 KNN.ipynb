{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d53ccdc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39msys\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "with open('data/iris.names', \"r\") as f:\n",
    "    dialog = \"\"\n",
    "    for i in f.readlines():\n",
    "        dialog += i\n",
    "print(dialog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c8931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris_df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\", header=None)\n",
    "iris_df = pd.read_csv('data/iris.data', header=None)\n",
    "print(iris_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764b9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eb34ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 라벨 추출\n",
    "y = iris_df.iloc[:, 4].values\n",
    "\n",
    "# 꽃받침의 길이와 꽃잎 길이등의 데이터 추출\n",
    "X = iris_df.iloc[:, :4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341ef4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f479be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_lst = list(set(y))\n",
    "label_dict = {label_name : label_index for label_index, label_name in enumerate(label_lst)}\n",
    "\n",
    "Y = np.array([label_dict[name] for name in y])\n",
    "print(set(y))\n",
    "print(label_dict)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a2fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class OneHotEncoder(object):\n",
    "    r\"\"\"\n",
    "    OneHotEncoder make one hot encoding for input class list\n",
    "    \"\"\"\n",
    "    def __init__(self, class_lst:list= None )->None:\n",
    "        assert class_lst is not None, f\"Must be input num or class_lst\"\n",
    "        self.word2idx = defaultdict()\n",
    "\n",
    "        class_lst = set(class_lst)\n",
    "        for idx, name in enumerate(class_lst):\n",
    "            self.word2idx[name] = idx\n",
    "            \n",
    "        self.make_matrix(len(class_lst))\n",
    "\n",
    "    \n",
    "    def make_matrix(self, num):\n",
    "        self.one_hot_matrix = np.eye(num)\n",
    "    \n",
    "    def __call__(self, cls):\n",
    "        return self.one_hot_matrix[self.word2idx[cls]]\n",
    "\n",
    "encoder = OneHotEncoder(y)\n",
    "Y       = np.array([encoder(i) for i in y])\n",
    "print(Y)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d8c871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded83144",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "rows,cols = X.shape\n",
    "index_lst = [[i, j] for i in range(0, cols) for j in range(i+1, cols)]\n",
    "colors = [\"r\",\"g\",\"b\"]\n",
    "labels = list(set(y))\n",
    "names  = [\"Sepal Length\", \"Sepal Width\", \"Petal Length\", \"Petal Width\"]\n",
    "print(index_lst)\n",
    "\n",
    "fig, ax = plt.subplots(2,3, figsize=(16,8))\n",
    "\n",
    "for r in range(2):\n",
    "    for c in range(3):\n",
    "        com_idx = r * 3 + c\n",
    "        i, j  = index_lst[com_idx]\n",
    "        for idx, label in enumerate(labels):\n",
    "            data = X[y == label,:]\n",
    "            data = data[:, [i,j]]\n",
    "            ax[r,c].scatter(data[:,0], data[:,1], c=colors[idx], label=label)\n",
    "            ax[r,c].set_xlabel(names[i])\n",
    "            ax[r,c].set_ylabel(names[j])\n",
    "        \n",
    "        ax[r,c].legend()\n",
    "        ax[r,c].grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed70771",
   "metadata": {},
   "outputs": [],
   "source": [
    "class randomSplit(object):\n",
    "    r\"\"\"\n",
    "    Make Random Split using index list for iris data\n",
    "    \"\"\"\n",
    "    def __init__(self, datasets:np.array, labels:np.array, split_rate:float=0.8)->None:\n",
    "        self.datasets = datasets\n",
    "        self.labels   = labels\n",
    "        self.split_rate = split_rate\n",
    "        self.make_index()\n",
    "        \n",
    "    def make_index(self):\n",
    "        # Make Index List and Shuffle\n",
    "        cls_idx_lst = np.arange(0,150).reshape(3,-1)\n",
    "        list(map(np.random.shuffle, cls_idx_lst))\n",
    "        \n",
    "        # Compute Split Value\n",
    "        n_cls, n_instance = np.shape(cls_idx_lst)\n",
    "        train_value = int(n_instance * self.split_rate)\n",
    "        \n",
    "        # Make list\n",
    "        self.train_lst = cls_idx_lst[:, :train_value].flatten()\n",
    "        self.valid_lst = cls_idx_lst[:, train_value:].flatten()\n",
    "    \n",
    "    def shuffle(self):\n",
    "        np.random.shuffle(self.train_lst)\n",
    "        np.random.shuffle(self.valid_lst)\n",
    "    \n",
    "    def __call__(self):\n",
    "        return (self.datasets[self.train_lst, :], self.labels[self.train_lst]), \\\n",
    "                (self.datasets[self.valid_lst, :], self.labels[self.valid_lst])\n",
    "\n",
    "\n",
    "dataloader = randomSplit(X, Y)\n",
    "train, valid = dataloader()\n",
    "dataloader.train_lst\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6360b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x:np.array, y:np.array) -> np.array:\n",
    "    r\"\"\"\n",
    "    Args :\n",
    "        x : np array(4, )\n",
    "        y : np.array(B, 4), B is Number of Training Dataset\n",
    "    Returns:\n",
    "        np.array(B,)\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum(np.square(x - y), axis=1)).T\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9823a146",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN(object):\n",
    "    r\"\"\"\n",
    "    Simple K-NN algorithm for iris dataset.\n",
    "    Just using numpy and Euclidean Distance\n",
    "    \"\"\"\n",
    "    def __init__(self, k:int, datasets:np.array, labels:np.array)->None:\n",
    "        self.k = k \n",
    "        self.datasets = datasets\n",
    "        self.labels   = labels\n",
    "        self.compute  = euclidean_distance\n",
    "        self.label2name  = {j:i for i, j in label_dict.items()}\n",
    "\n",
    "    def __call__(self, data:np.array)->np.array:\n",
    "        distance  = self.compute(data, self.datasets)\n",
    "        score_idx = np.argsort(distance)[:self.k]\n",
    "        k_labels  = self.labels[score_idx]\n",
    "        k_counts  = Counter(k_labels)\n",
    "        inf_labels= list(k_counts.keys())[0]\n",
    "        inf_name  = self.label2name[inf_labels]\n",
    "        return inf_labels, inf_name\n",
    "\n",
    "\n",
    "knn = KNN(3, train[0], train[1])\n",
    "print(knn(valid[0][0]))\n",
    "print(valid[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a406e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows,cols = X.shape\n",
    "index_lst = [[i, j] for i in range(0, cols) for j in range(i+1, cols)]\n",
    "colors = [\"r\",\"g\",\"b\", \"k\"]\n",
    "labels = list(set(y))\n",
    "names  = [\"Sepal Length\", \"Sepal Width\", \"Petal Length\", \"Petal Width\"]\n",
    "print(index_lst)\n",
    "\n",
    "fig, ax = plt.subplots(2,3, figsize=(16,8))\n",
    "\n",
    "for r in range(2):\n",
    "    for c in range(3):\n",
    "        com_idx = r * 3 + c\n",
    "        i, j  = index_lst[com_idx]\n",
    "        for idx, label in enumerate(labels):\n",
    "            data = X[y == label,:]\n",
    "            data = data[:, [i,j]]\n",
    "            ax[r,c].scatter(data[:,0], data[:,1], c=colors[idx], label=label)\n",
    "            ax[r,c].set_xlabel(names[i])\n",
    "            ax[r,c].set_ylabel(names[j])\n",
    "            \n",
    "        valid_data = valid[0]\n",
    "        valid_data = valid_data[:, [i,j]]\n",
    "        ax[r,c].scatter(valid_data[:,0][0],valid_data[:,1][1], c=colors[-1], label=\"validation\")\n",
    "        ax[r,c].legend()\n",
    "        ax[r,c].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f35fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(x:np.array, y:np.array) -> float:\n",
    "    r\"\"\"\n",
    "    Accurcay Function is metric function, for iris dataset\n",
    "    Args :\n",
    "        x : np.array(B,) has inference labels, B is number of dataset\n",
    "        y : np.array(B,) has real labes, B is number of dataset\n",
    "    Return : \n",
    "        float value how to many access for inferencing\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    count = np.sum(np.array(x == y).astype(np.int64)) \n",
    "    return (count/n) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d83e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(zip(valid[0], valid[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee046828",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN(3, train[0], train[1])\n",
    "\n",
    "inference = []\n",
    "for data in valid[0]:\n",
    "    labels, names = knn(data)\n",
    "    inference.append(labels)\n",
    "inference = np.array(inference)\n",
    "\n",
    "print(f\"붓꽃 데이터셋의 최종 성능 : {Accuracy(inference, valid[1]):.4f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce802cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5, p=2, metric=\"minkowski\")\n",
    "knn.fit(train[0], train[1])\n",
    "knn.predict(valid[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
